{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf463ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "#from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('03_non_padded_with_batch_info.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = max(np.unique(data.batchSize))\n",
    "batch = data.loc[data.batchSize == batchSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.head()\n",
    "X_train = batch.drop(['Target', 'Asset_ID', 'timestamp'], axis = 1).to_numpy()\n",
    "Y_train = batch.Target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy lstm model\n",
    "n_a = 64\n",
    "n_values = X_train.shape[1]\n",
    "reshapor = Reshape((1, n_values))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(1, activation='softmax')     # Used in Step 2.D\n",
    "# Tx = length of sequence / batch\n",
    "# n_a = number activations \n",
    "# n_values = feature number\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras model with the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "#     a0 = Input(shape=(n_a,), name='a0')\n",
    "#     c0 = Input(shape=(n_a,), name='c0')\n",
    "#     a = a0\n",
    "#     c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda x: X[:,t,:])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(x)#, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        #print(out.shape)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=X,outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = djmodel(100 , n_a = 64, n_values = X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bf876",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train_re[0:100])\n",
    "Y = []\n",
    "for i in Y_train[0:100]:\n",
    "    Y.append([[i]])\n",
    "\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_re = np.reshape(X_train, (1,X_train.shape[0], X_train.shape[1]))\n",
    "Y_train_re = np.reshape(Y_train, (1,Y_train.shape[0], 1))\n",
    "print(X_train_re[:,0,:], Y_train_re[:,0:10].shape)\n",
    "list1 = []\n",
    "list1.append(list(Y_train_re[:,0:100].astype(np.float32)))\n",
    "#print(list1)\n",
    "model.fit(X_train_re[:,0:100,:], Y, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention model\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context\n",
    "\n",
    "n_a = 32\n",
    "n_s = 64\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for the decoder LSTM of shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. Remember to use return_sequences=True. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True),input_shape=(m, Tx, n_a*2))(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(context, initial_state = [s, c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e24256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n",
    "opt =  Adam(lr=0.005, beta_1=0.9, beta_2=0.999,decay=0.01)\n",
    "model.compile(opt, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
